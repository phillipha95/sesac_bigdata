{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d642798",
   "metadata": {},
   "source": [
    "## GridSearch를 이용한 머신러닝 Hyperparameter 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceabbbb",
   "metadata": {},
   "source": [
    "#### https://teddylee777.github.io/scikit-learn/grid-search-%EB%A1%9C-hyperparameter%EC%B5%9C%EC%A0%81%ED%99%94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851d04e",
   "metadata": {},
   "source": [
    "#### Hyperparameter 튜닝을 위해서는 다양한 방법론이 존재합니다. 가장 쉬운 방법으로는 일명 손튜닝이 있을 수 있겠구요. RandomSearch, GridSearch, HyperOpt등 다양한 방법으로 Hyperparameter를 튜닝할 수 있습니다.\n",
    "\n",
    "그럼, Hyperparameter 튜닝을 할 때 위에 언급한 방법론들을 적용하는 이유는 뭘까요?\n",
    "\n",
    "답은 매우 간단합니다.\n",
    "\n",
    "사람이 직접 손튜닝을 하다보면, 실수를 할 수도 있고, 시간과 정신적 소모가 매우 큽니다.\n",
    "\n",
    "우리는 우리가 가진 훌륭한 컴퓨터 자원을 활용하여 Hyperparameter를 찾아가는 과정을 자동화하고, 우리가 잠이 든 사이 컴퓨터는 Best Parameter를 우리에게 제시해 줍니다.\n",
    "\n",
    "그 중 이번 포스팅에서는 가장 많이 활용되고 있는 GridSearch에 대하여 알아보고 이를 통해 Hyperparameter의 Best Parameter를 찾는 과정을 알려드리도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999bbc6",
   "metadata": {},
   "source": [
    "## GridSearch?\n",
    "GridSearch 는 우리가 지정해준 몇 가지 잠재적 Parameter들의 후보군들의 조합 중에서 가장 Best 조합을 찾아줍니다. 어떻게 보면 우리가 하나하나 대입해 가면서 loss를 확인하는 작업을 GridSearch는 대신 해준다고 보면 됩니다. 또한, sklearn 패키지에서 제공해주고 있기때문에 매우 손쉽게 사용할 수 있습니다.\n",
    "\n",
    "하지만, 가장 큰 단점은 우리가 지정해 준 hyperparameter 후보군의 갯수만큼 비례하여 시간이 늘어기 때문에 최적의 조합을 찾을 때까지 시간이 매우 오래 걸린다는 단점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507bb5d",
   "metadata": {},
   "source": [
    "### GridSearch 활용 예제\n",
    "GridSearch는 sklearn 패키지의 model_selection에 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d5a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_iris # 샘플 데이터 로딩\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b1d8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample\n",
    "dataset = load_iris()\n",
    "\n",
    "data = dataset['data']\n",
    "target = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb766250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, target, test_size=0.2, shuffle=True, stratify=target, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0b8a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch가 찾을 parameter를 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [None, 6, 9, 12],\n",
    "    'min_samples_split': [0.01, 0.05, 0.1],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a83f73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용할 estimator (모델)를 정의\n",
    "estimator = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9850df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(random_state=30,\n",
    "           n_splits=10,\n",
    "           shuffle=True,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6217f0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=30, shuffle=True),\n",
       "             estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 6, 9, 12],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_split': [0.01, 0.05, 0.1],\n",
       "                         'n_estimators': [100, 150, 200, 250]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch를 실행해 주면 됩니다. n_jobs=-1로 지정해주면 모든 코어를 다 사용하기때문에 컴퓨터는 뜨거워지겠지만, 속도는 많이 빨라집니다. verbose로 log 출력의 level을 조정 (숫자가 클 수록 많은 log 출력) 해 줄 수 있습니다.\n",
    "# define grid_search\n",
    "grid_search = GridSearchCV(estimator=estimator, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=kf, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=2\n",
    "                          )\n",
    "\n",
    "# fit with (x_train, y_train)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb894e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 0.1,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Parameter의 결과값 확인\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70266f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
